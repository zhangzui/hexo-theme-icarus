---
title: 网络运输层
date: 2018-11-20 23:40:44 #文章生成時間
categories:
    - 网络运输层 TCP UDP
tags:
  - 网络运输层
  - TCP
  - UDP
description: 网络运输层TCP&UDP
---

    今天想尝试写一下TCP相关的知识总结，感觉这是一个很复杂的东西，这里是TCP的最基本的知识
![](/images/tcp.jpeg "")
<!--more-->

# 简介TCP&UDP
## 1.其中包括两个协议，都是运输层的协议。
  TCP（Transmission Control Protocol，传输控制协议）:TCP是面向连接的
  UDP（User Data Protocol，用户数据报协议）：UDP它是面向非连接的协议，

## 2.TCP协议的特点
```
1.TCP 是面向连接的运输层协议。
2.每一条 TCP 连接只能有两个端点(endpoint)，每一条 TCP 连接只能是点对点的（一对一）。
3.TCP 提供可靠交付的服务。
4.TCP 提供全双工通信。
5.面向字节流。
TCP 连接是一条虚连接而不是一条真正的物理连接。
TCP 对应用进程一次把多长的报文发送到TCP 的缓存中是不关心的。
TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。
TCP 可把太长的数据块划分短一些再传送。TCP 也可等待积累有足够多的字节后再构成报文段发送出去。
```
## 3.UDP协议
1.UDP 只在 IP 的数据报服务之上增加了很少一点的功能，即端口的功能和差错检测的功能。
2.虽然 UDP 用户数据报只能提供不可靠的交付，但 UDP 在某些方面有其特殊的优点
  UDP 是无连接的，即发送数据之前不需要建立连接。
  UDP 使用尽最大努力交付，即不保证可靠交付，同时也不使用拥塞控制。
  UDP 是面向报文的。UDP 没有拥塞控制，很适合多媒体通信的要求。
  UDP 支持一对一、一对多、多对一和多对多的交互通信。
  UDP 的首部开销小，只有 8 个字节
3.发送方 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。应用层交给 UDP 多长的报文，UDP 就照样发送，即一次发送一个报文。接收方 UDP 对 IP 层交上来的 UDP 用户数据报，在去除首部后就原封不动地交付上层的应用进程，一次交付一个完整的报文。应用程序必须选择合适大小的报文。
## 4.TCP报文格式
![图片说明-UDP报文](/images/png/UDP报文.png "UDP报文")

## 5.UDP报文格式
![图片说明-UDP报文](/images/png/UDP报文.png "UDP报文")

***
# TCP可靠传输原理
## 1.停止等待协议
    就是发送完一个分组数据之后，就停止发送，等待对方确认，收到确认之后再发送下一个分组。要想理解TCP的可靠传输，首先需要理解这个停止等待协议，这是最简单的可靠传输通信协议，TCP并不是简单的这个协议，为了理解，首先引入该协议。

    ![停止等待协议-1](/images/png/停止等待协议1.png "停止等待协议-1")
    1.图中1-a ，是没有差错的传输，A发送M1，M2，M3 B都收到并发送确认收到
    ![停止等待协议-2](/images/png/停止等待协议2.png "停止等待协议-2")

    2.图中1-b，是A发送M1，大于接收确认结果超时时间（这里A会设置一个超时重传时间，超过没有接收到确认则超时重传），在重传M1，成功之后继续。
    注意：1.A发送完分组之后，必须保留发送完的副本，只有收到确认再清除该副本;
      (a).分组和确认分组都必须进行编号;
      (b).超时计时器设置的超时时间必须比正常平均往返时间长一点。
    3.图2-a：是B接收到A的数据，但是b发送的M1确认丢失，此时A超时再次发送M1，B此时需要在接收M1，需要注意：
        (a).丢弃这个重复的分组，不往上层交付
        (b).发送M1的确认结果，让M1收到确认，解除重传。
    4.图2-b：就是确认迟到。就是B发送的M1确认结果迟到，A接收到了两次M1确认，则收到确认什么也不做。

## 2.连续ARQ协议
    上面讲到了停止等待协议，优点就是简单可靠，但是信道利用率低。所以为了提高信道利用率，就出现了连续发送多个分组，不是一一等待确认结果，这样大大的提高了信道利用率，这种方式就是连续ARQ协议和滑动窗口协议。滑动窗口协议是TCP可靠传输的精髓，但是连续ARQ协议并不是TCP的实现方案。只是运用了连续发送，和窗口的概念。连续ARQ协议就是一次性发送多个连续的分组，等收到确认的结果之后，将发送窗口向后移动，继续发送一个多分组的窗口数据。有优点就是简单，但是不能正确的发送确认窗口所有分组的正确接收信息。

## 3.滑动窗口协议
    TCP的可靠传输的实现是原理是滑动窗口，基于字节为单位：
    ![滑动窗口-1](/images/png/滑动窗口1.png "滑动窗口-1")
    1.TCP接收上层应用的数据，将其放入缓存中，然后根据网络环境和接收方可处理数据能力综合计算出一个合适的发送窗口。发送方的缓存用于保存应用发给TCP还未来的及发送的数据和发送了但是没有收到确认的缓存数据。

    ![滑动窗口-2](/images/png/滑动窗口2.png "滑动窗口-2")
    2.TCP接收方也是先将接收到的报文放入接收缓存中，等到接收完一个连续的序号字节报文，然后选择何时的时间发送确认结果，一般时间不超过0.5秒。但是也可以等自己需要发送响应数据的时候顺带稍上确认结果报文，但是这种情况一般很少，但是这样是被允许的。

    ![滑动窗口-3](/images/png/滑动窗口3.png "滑动窗口-3")
    3.接收方TCP缓存的数据：按序到达但是没有被应用及时处理的数据，还有就是没有按序到达的数据。

注意：
    (1).A 的发送窗口并不总是和 B 的接收窗口一样大（因为有一定的时间滞后）。
    (2).TCP 标准没有规定对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。
    (3).TCP 要求接收方必须有累积确认的功能，这样可以减小传输开销。

***
# 超时重传时间的选择
    重传机制是TCP的最重要也是最复杂的问题之一。
## 1.加权平均往返时间（RTTs）：
    Old RTTs：老的Rtts时间
    New RTTs ：新的加权平均时间样本
    New RTTs = （1-a）* Old RTTs + a*(New RTTs)
    式中，0 <= a <1。若a很接近于零，表示 RTT 值更新较慢。若选择a接近于 1，则表示 RTT 值更新较快。RFC 2988 推荐的  值为 1/8，即 0.125
    第一次直接去往返时间的值。
## 2.超时重传时间的计算（RetransmissionTime-Out）：
    RTO理应比加权平均数大，这样超时重传才有意义。所以在RFC2088中建议这样来计算超时重传时间
    RTO = RTTs + 4*RTT(D)
    RTTD:是RTT的偏差加权平均数。文档中计算该值的方法是：第一次使用测量值的一半，往后有了新的记录值则：
    RTTD = (1-b) * 旧的RTTD + b*|RTTS-新的RTT样本值|
    b是小于1的系数，推荐值是1/4
## 3.Karn 算法
    问题，如果重传了，是不是计算的往返加权平均值就不准确了。
    所以出现Karn 算法，则该次的往返时间的样本数值不参与计算，这样避免计算误差。而且报文每发生一次重传，就把RTO（超时时间）增大一些。
    即：新的RTO = Y*(旧的RTO)，系数Y的典型值是2，所以这样直到不发生重传，才取往返的时延更新RTT和超时重传时间RTO。
## 4.总结：
    超时重传时间计算：
    1.第一次没有记录值：
        取第一次的往返时间 T0：
        RTTS_1 = T0;
        RTTD_1 = RTTS_1/2 = T0/2
        RTO_1 = RTTS_1 +（T0/2 ×4）
    2.不超时的情况：
        第二往返时间 T1：
        RTTS_2 = （1-1/8）× RTTS_1 + （1/8×T1）
        RTTD_2 = (1-1/4) * RTTD_1 + b*|RTTS_1-RTTS_2|
        RTO_2 = RTTS_2 + （RTTD_2 ×4）
    3.超时的情况
        第三次往返时间 T2：
        新的RTO = 2*(RTO_2)
        ...

***
# TCP的选择确认
    TCP可以支持选择确认：就是接收方收到不连续的字节流块，如果这些序列号都在接收窗口之内，那么接收方可以先存下这些数据，并准确的将接收信息发送给发送端，这样发送方就可以不需要再次发送这些数据。
    TCP如果要使用选择确认，必须建立连接的时候需要允许 SACK在首部的选项中加上”允许 SACK“ 的选项，由于TCP的首部选项中最多只能有40个字节，而指明一个边界就需要使用4个字节，则在使用选择确认接收时，只能带上8个边界信息，所以只有四个字节块的选择确认信息可以被选择确认。

***
# TCP的流量控制
    利用滑动窗口的机制实现TCP的流量控制。它的作用就是让发送方发送的不要太快，既要满足接收方的处理速度，还不能让网络发送堵塞。
    我们看一下简单的例子：A->B
    A和B建立连接是，B告诉A，我的接收处理窗口是400字节，然后每次传输过程中，B都会实时根据自己的处理能力和网速状态进行发送流量控制，这里就是通过发送流量控制消息给A
    来通知A的发送，如果B告诉A，当前的处理窗口大小，然后A就会在达到窗口大小之后就会停止。
    如果B通知A一个O处理窗口，则A就会一直等待B发送大于0的处理窗口响应，TCP为每一个连接设置一个持续计时器，就是当接收窗口发送了0窗口处理响应时，就需要启动该持续计时器，该计时器定时的会发送一个探测报文段（携带一个字节），对方确认时就要给出当前的处理窗口大小，
    如果还是0,则继续等待，如果大于0，则僵局被打破（该计时器，方式网络延时和数据丢包的情况下，窗口处理响应消息对方一直收不到，导致陷入无限等待的僵局，有了定时探测则可以避免偶尔的消失延时导致发送方迟迟收不到大于0的窗口通知）

***
# 传输效率分析：
## 1.发送报文段的时机选择：
    问题，就是发送方缓存中接到一个字节就开始发送，接收方同样的，收到一个字节就确认，导致网络带宽并不富裕的情况下，这种传输效率太低。
TCP的实际中广泛使用Nagle算法。如果应用逐个字节发送到TCP缓存，则将第一个字节先发送出去，将后边的字节缓存起来，当收到确认时，则将后续缓存的数据大量发出去，然后等待确认，并接受应用下发的字节缓存。
还有该算法指明，当到达的数据大于窗口的一半以上，就立即发送一个报文段。

## 2.糊涂窗口综合症问题：
    TCP的接收方缓存已满，每次只能处理一个字节，这样导致每次确认一个字节，并响应一个字节处理，导致传输效率极低。
处理该问题，可以让接收方等待一段时间，等待接收方TCP缓存可以容纳一个窗口的大小，或者更大的缓存空间，如果出现其中一个情况，接收方才发送确认报文，并发送当前的窗口大小。
发送方也是同样的道理，每次发送等到缓存中有足够多的数据才发送。以上是TCP的传输效率相关的优化。

***
# TCP的拥塞控制
## 1.拥塞
    当网络中的带宽，交换节点间的缓存和相关处理机构成了网络的资源，当这些资源满足不了当前需要传送的数据时或者当前所需的资源时，则会出现网络拥塞。
网络拥塞的原因：节点的缓存容量太小，如果没有暂存空间，则到达该节点的分组数据可能会丢弃，如果输出链路的容量和处理机的容量不够同样会导致拥塞，这样上层应用需要进行分组重传，从而也会导致TCP连接之间分组的超时拥塞和超时重传.
拥塞控制就是为了解决上述问题，当网络资源有限的情况下如何控制拥塞。所谓的拥塞控制就是防止过多的数据注入到网络中，造成网络拥堵，传输效率低。与流量控制不一样，
流量控制是点对点和端对端的，控制发送端发送数据的速度，以便接收端能处理的过来。但是拥塞控制是整个的传输过程中的网络现有资源和所需资源的比较和控制。

## 2.拥塞控制的几种方法：
    发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。如再考虑到接收方的接收能力，则发送窗口还可能小于拥塞窗口。
发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。
![阻塞避免](/images/png/阻塞避免.png "阻塞避免")

## 3.慢开始算法的原理
    a.在主机刚刚开始发送报文段时可先设置拥塞窗口 cwnd = 1，即设置为一个最大报文段 MSS 的数值。
    b.在每收到一个对新的报文段的确认后，将拥塞窗口加 1，即增加一个 MSS 的数值。
    c.用这样的方法逐步增大发送端的拥塞窗口 cwnd，可以使分组注入到网络的速率更加合理。
慢开始的示例：
![慢开始示例](/images/png/慢开始示例.png "慢开始示例")
    慢开始算法，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间 RTT;“传输轮次”更加强调：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。
## 4拥塞避免：
    设置慢开始门限 ssthresh用法如下：
    (1).当 cwnd < ssthresh 时，使用慢开始算法。
    (2).当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
    (3).当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。
    拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。
无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门限 ssthresh 设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。
然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。

### (a).加法增大：是指执行拥塞避免算法后，在收到对所有报文段的确认后（即经过一个往返时间），就把拥塞窗口 cwnd增加一个 MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。
    (b).乘法减小：是指不论在慢开始阶段还是拥塞避免阶段，只要出现一次超时（即出现一次网络拥塞），就把慢开始门限值 ssthresh 设置为当前的拥塞窗口值乘以 0.5。
    当网络频繁出现拥塞时，ssthresh 值就下降得很快，以大大减少注入到网络中的分组数。
    注意：
    “拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。
    “拥塞避免”是说在拥塞避免阶段把拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞

## 5.快重传和快恢复
### A.快重传算法
    (1).接收方每收到一个失序的报文段后就立即发出重复确认。这样做可以让发送方及早知道有报文段没有到达接收方。
    (2).发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。
    (3).不难看出，快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。
### B.快恢复算法
    ![快恢复展示](/images/png/快恢复.png "快恢复展示")
    当发送端收到连续三个重复的确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。但接下去不执行慢开始算法。由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，即拥塞窗口 cwnd 现在不设置为 1，而是设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。
## 6.发送窗口的上限值
    发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定：
    发送窗口的上限值 = Min [rwnd, cwnd]
    当 rwnd < cwnd 时，是接收方的接收能力限制发送窗口的最大值。
    当 cwnd < rwnd 时，则是网络的拥塞限制发送窗口的最大值。

***
# 随机早期检测RED（Random Early Detection）
## a.为啥要出现随机早期检测，又称之为随机早期分组丢弃？
    因为通常路由器的缓存数据队列是先进先出的，并且队列满了之后会遵循尾部丢弃策略。所以一旦网络各个TCP连接依赖的路由器，到达该路由器的数据，并且路由器缓存队列已满，来不及处理，此时所有的TCP连接上的分组报文数据都将同时丢弃。
    也就是此时TCP所有的连接都同时进入慢开始状态，TCP术语称之为全局同步。使得全网的通讯质量突然下降，等恢复以后，其通讯量又突然增大，带来的网络传输体验不够平滑友好。所以就出现了随机提前检测的机制。
## b.如何实现RED？
    它的实现机制是让路由器的队列维护两个参数，一个最小门限TH(min),和一个最大门限TH(max)。当每一个分组到达时，RED先计算出一个平均长度L(AV)，为什么要使用平均队列长度呢？因为计算机数据具有突发性和不稳定的特点，队列的长度起伏变化很快。
    1.当L(AV) < TH(min),则直接让其排队。
    2.当L(AV) > TH(max),则直接丢弃。
    3.当TH(min) < L(AV) < TH(max),则通过计算一个丢弃概率P来随机丢弃该分组。
    这样的做的好处，就是在出现网络拥塞之前（拥塞征兆），让部分TCP连接先进入慢开始状态，这样避免全局性的进入阻塞控制。

## c.如何计算丢弃概率p和平均队列长度？
    1.最小门限设置应该足够大，这样保证正常的传输效率，最大和最小的差值也要足够大，使得一个TCP往返时间RTT的队列正常增长在最大值以内。
        最大门限等于最小门限的两倍最为合适。
    2.平均队列长度 = （1-a）*旧的队列长度+ a*当前样本值。
        a如果很小，说明当前的样本所占的比例就小，平均值取决与之前的长时间变化数据，不受时间短的数据突发情况。
    3.丢弃概率P = P1/(1- count*P1)

    P1是过度分组的丢弃概率：P1 = P(Max) *(L(av)-TH(min)) /(TH(max)-TH(min))
    count：是已经进入队列的分组数。
    P(max)：是设置的最大概率参数。
    所以，丢弃的概率会随着平均的队列长度增大而加大。
## d.总结RED
    随机早期检测的好处就是当部分TCP连接到达的数据导致平均队列长度大于TH（min），就会又概率丢弃分组，使得少量的TCP连接减少发送窗口，或者直接进入慢开始状态。
    这样路由器的缓存队列就会得到缓解，平均队列长度随之就会减小，有效的避免了网络拥塞的发生。这样就会让网络的吞吐量保持在一个较高的水平，保证极少数的分组被丢弃。

***
# TCP的连接管理
    TCP的连接管理，是TCP的重中之重，分为三个部分：建立连接，数据传输，释放连接。
## 1.建立连接
    (1).A 的 TCP 向 B 发出连接请求报文段，其首部中的同步位 SYN = 1，并选择序号 seq = x，表明传送数据时的第一个数据字节的序号是 x。
    (2).B 的 TCP 收到连接请求报文段后，如同意，则发回确认。B 在确认报文段中应使 SYN = 1，使 ACK = 1，其确认号ack = x  1，自己选择的序号 seq = y
    (3).A 收到此报文段后向 B 给出确认，其 ACK = 1，确认号 ack = y  1。A 的 TCP 通知上层应用进程，连接已经建立。B 的 TCP 收到主机 A 的确认后，也通知其上层应用进程：TCP 连接已经建立
![建立连接](/images/png/握手.png "建立连接")
## 2.释放连接:
    (1).数据传输结束后，通信的双方都可释放连接。现在 A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭 TCP连接。A 把连接释放报文段首部的 FIN = 1，其序号seq = u，等待 B 的确认。
    (2).B 发出确认，确认号 ack = u+1，而这个报文段自己的序号 seq = v。TCP 服务器进程通知高层应用进程。从 A 到 B 这个方向的连接就释放了，TCP 连接处于半关闭状态。B 若发送数据，A 仍要接收。
    (3).若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。
    (4).A 收到连接释放报文段后，必须发出确认。在确认报文段中 ACK = 1，确认号 ack =w+1，自己的序号 seq = u + 1
    ![释放连接](/images/png/挥手.png "释放连接")
### 3.注意：
    TCP 连接必须经过时间 2MSL 后才真正释放掉。
    第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。
    第二，防止 “已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失。
    这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段
### 4.问题：

#### 1.为什么需要三次握手和四次挥手？
    （1）连接建立过程中要解决以下三个问题：
        a.要使每一方能够确知对方的存在:所以三次握手。
        b.要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。
        c.能够对运输实体资源（如缓存大小，连接表中的项目等）进行分配。
    （2）要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。
    参考链接：[TCP 的那些事儿](https://coolshell.cn/articles/11564.html "TCP 的那些事儿")

#### 2.seq序列号生成规则：SeqNum的增加是和传输的字节数相关的

#### 3.TIME_WAIT状态是用来解决或避免什么问题呢？
    关于 MSL 和 TIME_WAIT。这个超时设置是 2*MSL（RFC793定义了MSL为2分钟，Linux设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？
    主要有两个原因：
    1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL
    2）有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。你可以看看这篇文章《TIME_WAIT and its design implications for protocols and scalable client server systems》

## 3.TCP的有限状态机
![有限状态机](/images/png/有限状态机.png "有限状态机")
    (1).蓝色箭头表示对客户进程的正常变迁。
    (2).红色箭头表示对服务器进程的正常变迁。
    (3).另一种细线箭头表示异常变迁
